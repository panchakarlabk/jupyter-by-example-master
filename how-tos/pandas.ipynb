{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Tips & Tricks\n",
    "\n",
    "This notebook presents various tricks to manipulate your data, which are typically non-obvious to a novice in Pandas and data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import time\n",
    "from IPython.display import HTML, clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple CSV Files\n",
    "\n",
    "This shows how to create a single dataframe from multiple files that share the same structure (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  11 ../data/commits1.tsv\n",
      "  12 ../data/commits2.tsv\n",
      "  23 total\n",
      "♯ 21\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = '../data/commits*.tsv'\n",
    "df = pd.concat([pd.read_csv(x, sep='\\t', parse_dates=['Date']) for x in glob.glob(files)], \n",
    "               ignore_index=True)\n",
    "\n",
    "!wc -l {files}\n",
    "print('♯', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.Author.unique()), len(pd.unique(df.Author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Dataframes\n",
    "\n",
    "Looking at the contents and metadata of your dataframes is quite important, to better understand the data they represent and then successfully transform it into the results you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data dimensions (rows, cols)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SHA                                      object\n",
       "Author                                   object\n",
       "Date       datetime64[ns, pytz.FixedOffset(60)]\n",
       "Message                                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at a sample, it is often useful to transpose the data, especially when you have many columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           0                            1\n",
      "SHA                                  8fe0ea9                      9de3457\n",
      "Author                              jhermann                     jhermann\n",
      "Date               2019-02-16 06:04:19+01:00    2019-02-16 05:57:50+01:00\n",
      "Message  :link: Python Data Science Handbook  add requirements for Binder\n"
     ]
    }
   ],
   "source": [
    "print(df.head(2).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then there is `describe` with some core statistics about the dataframe…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count unique                                              top freq  \\\n",
      "SHA        21     21                                          6454187    1   \n",
      "Author     21      2                                         jhermann   20   \n",
      "Date       21     21                        2019-02-15 21:23:05+01:00    1   \n",
      "Message    21     21  link to Netflix 'Notebook Innovation' blog post    1   \n",
      "\n",
      "                             first                       last  \n",
      "SHA                            NaN                        NaN  \n",
      "Author                         NaN                        NaN  \n",
      "Date     2019-02-11 16:06:17+01:00  2019-02-16 06:04:19+01:00  \n",
      "Message                        NaN                        NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "… and `info` with more technical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 4 columns):\n",
      "SHA        21 non-null object\n",
      "Author     21 non-null object\n",
      "Date       21 non-null datetime64[ns, pytz.FixedOffset(60)]\n",
      "Message    21 non-null object\n",
      "dtypes: datetime64[ns, pytz.FixedOffset(60)](1), object(3)\n",
      "memory usage: 752.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Results\n",
    "### Writing Spreadsheet Files\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Rows\n",
    "\n",
    "You can use [loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) in combination with a `bool` array to select a subset of rows. That array is conveniently created by applying conditions to columns.\n",
    "\n",
    "The first example uses regex matching…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date                                   Message\n",
      "7  2019-02-15 17:17:30+01:00               Altair: use non-random data\n",
      "8  2019-02-15 16:58:26+01:00  Altair: Publishing Charts with nbconvert\n",
      "10 2019-02-15 10:40:04+01:00                      Altair setup details\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df.Message.str.match('altair', case=False)]\n",
    "             .reindex(['Date', 'Message'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is using simple comparison operators, e.g. `!=` like here…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date         Message\n",
      "20 2019-02-11 16:06:17+01:00  Initial commit\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df.Author != 'jhermann']\n",
    "             .reindex(['Date', 'Message'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the condition creates a `bool` array, that then is taken by `loc[…]` to select the matching rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, True]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.Author.iloc[-5:] != 'jhermann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding or Replacing Columns\n",
    "Changing the values of a column or adding a whole new one can be done by actual assignment or by calling `assign`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ♯: 4 vs. 5\n",
      "                       Date                              Message  Words\n",
      "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook      5\n",
      "1 2019-02-16 05:57:50+01:00          add requirements for Binder      4\n"
     ]
    }
   ],
   "source": [
    "morecols = df.assign(Words=df.Message.str.split().apply(len))\n",
    "print('Column ♯:', len(df.columns), 'vs.', len(morecols.columns))\n",
    "print(morecols.head(2).iloc[:, -3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using assigment is inplace and changes the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date                              Message  Words  Zero\n",
      "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook      5     0\n",
      "1 2019-02-16 05:57:50+01:00          add requirements for Binder      4     0\n"
     ]
    }
   ],
   "source": [
    "morecols['Zero'] = 0\n",
    "print(morecols.head(2).iloc[:, -4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Columns\n",
    "This one's easy, just call [rename](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html). Columns can be specified in various formats, like a mapping from old to new. Renaming can also be done inplace, the default is to copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date                                 Text  Words  Zero\n",
      "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook      5     0\n"
     ]
    }
   ],
   "source": [
    "print(morecols.rename(columns=dict(Message='Text')).head(1).iloc[:, -4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rename all columns, just `zip` the existing names with the new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     0\n",
      "0                              8fe0ea9\n",
      "1                             jhermann\n",
      "2            2019-02-16 06:04:19+01:00\n",
      "3  :link: Python Data Science Handbook\n",
      "4                                    5\n",
      "5                                    0\n"
     ]
    }
   ],
   "source": [
    "numcols = morecols.rename(\n",
    "    columns=dict(zip(morecols.columns, \n",
    "                     range(len(morecols.columns)))))\n",
    "print(numcols.head(1).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rename according to some logic, like a regex substitution or similar, provide a mapper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           0\n",
      "SHA                                  8fe0ea9\n",
      "AUTHOR                              jhermann\n",
      "DATE               2019-02-16 06:04:19+01:00\n",
      "MESSAGE  :link: Python Data Science Handbook\n",
      "WORDS                                      5\n",
      "ZERO                                       0\n"
     ]
    }
   ],
   "source": [
    "print(morecols.rename(mapper=str.upper, axis=1).head(1).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Columns\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date                              Message\n",
      "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook\n"
     ]
    }
   ],
   "source": [
    "print(df[['Date', 'Message']].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Manipulation\n",
    "\n",
    "The new `Day` column is just the first word out of the `Date` column. By splitting with `expand=True` two columns are created (instead of one column with tuples), so we can select the first column only and add this to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date                              Message         Day\n",
      "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook  2019-02-16\n"
     ]
    }
   ],
   "source": [
    "df = df.assign(Day=df.Date.astype(str).str.split(n=1, expand=True)[0])\n",
    "print(df.head(1).iloc[:, -3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Date` is a `datetime64` column, we can also use the [DatetimeProperties](http://pandas.pydata.org/pandas-docs/version/0.15.0/api.html#datetimelike-properties) accessor for day extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date                              Message         Day\n",
      "0 2019-02-16 06:04:19+01:00  :link: Python Data Science Handbook  2019-02-16\n"
     ]
    }
   ],
   "source": [
    "df = df.assign(Day=df.Date.dt.date)\n",
    "print(df.head(1).iloc[:, -3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "\n",
    "To visualize data in bar or other magnitude charts, you have to count subsets of your raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/pandas-barh.png?1553947498.4294667\"></img>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commits_per_day = df.Day.value_counts().to_frame().sort_index()\n",
    "_ = commits_per_day.plot.barh(legend=False, figsize=(5, 2))\n",
    "\n",
    "chart_img = 'img/pandas-barh.png'\n",
    "plt.savefig(chart_img)\n",
    "clear_output()\n",
    "HTML('<img src=\\\"{}?{}\\\"></img>'.format(chart_img, time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "Grouping values by one or more columns and then applying an operation to fold those values into a single scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter   P    a    d    n    s\n",
      "Code    80  194  100  110  115\n"
     ]
    }
   ],
   "source": [
    "letters = list(\"Pandas\")\n",
    "codes = pd.DataFrame(dict(Letter=letters, Code=list(map(ord, letters))))\n",
    "codes = codes.groupby('Letter').aggregate(np.sum)\n",
    "print(codes.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `reset_index` moves the grouping column(s) from the index to ordinary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0    1    2    3    4\n",
      "Letter   P    a    d    n    s\n",
      "Code    80  194  100  110  115\n"
     ]
    }
   ],
   "source": [
    "codes = codes.reset_index()\n",
    "print(codes.transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
